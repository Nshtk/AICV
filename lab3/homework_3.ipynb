{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача №1 - Лес или пустыня?\n",
    "\n",
    "Часто при анализе изображений местности необходимо понять ее характер. В частности, если определить, что на изображении преобладет вода, то имеет смысл искать корабли на таком изображении. Если на картинке густой лес, то, возможно, это не лучшая зона для посадки дрона или беспилотника.\n",
    "\n",
    "Ваша задача - написать программу, которая будет отличать лес от пустыни. В приложении можно найти реальные спутниковые снимки лесов и пустынь.\n",
    "\n",
    "Примеры изображений:\n",
    "<table><tr>\n",
    "\t<td> <img src=\"https://i.ibb.co/nmHHctW/test_image_00.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "\t<td> <img src=\"https://i.ibb.co/dM77C4b/test_image_06.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_forest_desert=\"lab3/desert_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImagesFromDirectory(path : str, imread_mode=cv.IMREAD_COLOR) -> list[np.ndarray]:\n",
    "\timages=[]\n",
    "\t\n",
    "\tfor file_name in os.listdir(path):\n",
    "\t\tfile_name_full=f\"{path}/{file_name}\"\n",
    "\t\tif(os.path.isfile(file_name_full)):\n",
    "\t\t\ttry:\n",
    "\t\t\t\timages.append(cv.imread(file_name_full, imread_mode))\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\tpass\n",
    "\t\t\t\n",
    "\treturn images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaing histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classifyImages(classes_images_base : list[list[np.ndarray]], images : list[np.ndarray]) -> list[list[float]]:\n",
    "\t\"\"\"Classifies images based on average histogram of base images\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tclasses_images_base (list[list[np.ndarray]]): \n",
    "\t\timages (list[np.ndarray]): \n",
    "\n",
    "\tReturns:\n",
    "\t\tlist[list[float]]: Class probabilities for each image\n",
    "\t\"\"\"\n",
    "\tclasses_histograms=[]\n",
    "\thistogram_channels=[0, 1, 2]\n",
    "\thistogram_size=[256, 256, 256]\n",
    "\thistogram_range_r=[0, 256]; histogram_range_g=[0, 256]; histogram_range_b=[0, 256];\n",
    "\thistogram_range=histogram_range_r+histogram_range_g+histogram_range_b\n",
    "\timages_class_values=[]\n",
    "\t\n",
    "\tfor images_base in classes_images_base:\n",
    "\t\timages_base_histograms=[]\n",
    "\t\tfor image_base in images_base:\n",
    "\t\t\timage_base_histogram=cv.calcHist([image_base], histogram_channels, None, histogram_size, histogram_range)\n",
    "\t\t\tcv.normalize(image_base_histogram, image_base_histogram, 0, 1, cv.NORM_MINMAX)\n",
    "\t\t\timages_base_histograms.append(image_base_histogram)\n",
    "\t\tclasses_histograms.append(np.average(images_base_histograms, axis=0))\n",
    "\t\n",
    "\tfor image in images:\n",
    "\t\tclass_values=[]\n",
    "\t\tfor base_image_histogram in classes_histograms:\n",
    "\t\t\tclass_values.append(cv.compareHist(base_image_histogram, cv.calcHist([image], histogram_channels, None, histogram_size, histogram_range), 0))\n",
    "\t\timages_class_values.append(class_values)\n",
    "\t\n",
    "\treturn images_class_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 can be a forest.\n",
      "Image 0 is most likely a forest.\n",
      "Accuracies: [0.9814483085191159, -0.06401127337196623]\n",
      "Image 1 can be a forest.\n",
      "Image 1 is most likely a forest.\n",
      "Accuracies: [0.25325250696479124, -0.013189855398531592]\n",
      "Image 2 can't be classified.\n",
      "Accuracies: [0.048546379920778045, -0.018349830176498074]\n",
      "Image 3 can be a forest.\n",
      "Image 3 is most likely a forest.\n",
      "Accuracies: [0.534970642838238, -0.06320153042086536]\n",
      "Image 4 can be a desert.\n",
      "Image 4 is most likely a desert.\n",
      "Accuracies: [-0.054493664966895304, 0.8108632233060854]\n",
      "Image 5 can be a forest.\n",
      "Image 5 is most likely a forest.\n",
      "Accuracies: [0.6739402559411465, -0.05347165810441724]\n",
      "Image 6 can't be classified.\n",
      "Accuracies: [-0.03783977642680696, 0.033170830390727636]\n",
      "Image 7 can't be classified.\n",
      "Accuracies: [0.009036860154759057, -0.04510664721725452]\n",
      "Image 8 can be a forest.\n",
      "Image 8 is most likely a forest.\n",
      "Accuracies: [0.169777079154702, -0.01930765352768221]\n",
      "Image 9 can be a forest.\n",
      "Image 9 is most likely a forest.\n",
      "Accuracies: [0.6933133044056182, -0.040425297510473274]\n",
      "Image 10 can't be classified.\n",
      "Accuracies: [-0.017107639183453576, 0.00029864596019747096]\n",
      "Image 11 can't be classified.\n",
      "Accuracies: [-0.010126928295042897, 0.0003013712853743132]\n",
      "Image 12 can be a desert.\n",
      "Image 12 is most likely a desert.\n",
      "Accuracies: [-0.034275523893675164, 0.5766939385255451]\n",
      "Image 13 can't be classified.\n",
      "Accuracies: [-0.04399324244657663, -0.01607369985457606]\n",
      "Image 14 can't be classified.\n",
      "Accuracies: [-0.009991849197690444, 0.022597485273854603]\n",
      "Image 15 can't be classified.\n",
      "Accuracies: [-0.05321878485369888, -0.0017534074669264333]\n",
      "Image 16 can't be classified.\n",
      "Accuracies: [-0.028052011757353168, -0.015989250429200855]\n"
     ]
    }
   ],
   "source": [
    "class_names=[\"forest\", \"desert\"]\n",
    "classes_images_base=[\n",
    "\t[cv.imread(f\"{path_images_forest_desert}/test_image_00.jpg\"), cv.imread(f\"{path_images_forest_desert}/test_image_01.jpg\")], \n",
    "\t[cv.imread(f\"{path_images_forest_desert}/test_image_04.jpg\"), cv.imread(f\"{path_images_forest_desert}/test_image_12.jpg\")]\n",
    "]\n",
    "images=readImagesFromDirectory(path_images_forest_desert)\n",
    "images_class_values=classifyImages(classes_images_base, images)\n",
    "class_value_threshold=0.1\n",
    "\n",
    "i=0\n",
    "for image_class_values in images_class_values:\n",
    "\tclass_value_max=0\n",
    "\tj=0\n",
    "\tj_class_value_max=0\n",
    "\tfor class_value in image_class_values:\n",
    "\t\tif class_value>class_value_max:\n",
    "\t\t\tclass_value_max=class_value\n",
    "\t\t\tj_class_value_max=j\n",
    "\t\tif class_value>class_value_threshold:\n",
    "\t\t\tprint(f\"Image {i} can be a {class_names[j]}.\")\n",
    "\t\tj+=1\n",
    "\tif class_value_max>class_value_threshold:\n",
    "\t\tresult=f\"Image {i} is most likely a {class_names[j_class_value_max]}.\"\n",
    "\telse:\n",
    "\t\tresult=f\"Image {i} can't be classified.\"\n",
    "\tprint(result)\n",
    "\tprint(f\"Accuracies: {image_class_values}\")\n",
    "\tcv.imshow(result, images[i])\n",
    "\tcv.waitKey(0)\n",
    "\tcv.destroyAllWindows()\n",
    "\ti+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача №2 - Реализовать Image-blending на основе сшивки по градиентам\n",
    "\n",
    "Задача - взять фото двух лиц : ваше и друга, с помощью метода Poisson image editing совместить глаза, нос и рот с первого изображения со вторым. Суть в том, что при использовании такого метода границы совмещенного изображения не видны.\n",
    "\n",
    "Статья, где описан метод  \n",
    "\n",
    "Patrick Pérez, Michel Gangnet, and Andrew Blake. 2003. Poisson image editing. ACM Trans. Graph. 22, 3 (July 2003), 313–318. https://doi.org/10.1145/882262.882269\n",
    "\n",
    "Пример такого совмещения:\n",
    "\n",
    "<img src=\"blending/blending.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_cups=\"lab3/cups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=readImagesFromDirectory(path_images_cups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blendImages(image_1 : np.ndarray, image_2 : np.ndarray) -> np.ndarray:\n",
    "\timages=[image_1, image_2]\n",
    "\ttuples_pyramides_gauss_laplace=[]\n",
    "\trg=5\n",
    "\t\n",
    "\tfor image in images:\n",
    "\t\timage_copy=image.copy()\n",
    "\t\tpyramid_gauss = [image_copy]\n",
    "\t\tfor i in range(rg):\n",
    "\t\t\timage_copy=cv.pyrDown(image_copy)\n",
    "\t\t\tpyramid_gauss.append(image_copy)\n",
    "\t\t\t\n",
    "\t\tpyramid_laplace = [pyramid_gauss[rg - 1]]\n",
    "\t\tfor i in range(rg - 1, 0, -1):\n",
    "\t\t\tupsample = cv.pyrUp(pyramid_gauss[i])\n",
    "\t\t\tpyramid_gauss[i-1] = np.pad(pyramid_gauss[i-1], pad_width=[(0, abs(upsample.shape[0]-pyramid_gauss[i-1].shape[0])), (0, abs(upsample.shape[1]-pyramid_gauss[i-1].shape[1])), (0, 0)], mode='edge')\n",
    "\t\t\tpyramid_laplace.append(cv.subtract(pyramid_gauss[i-1], upsample))\n",
    "\t\ttuples_pyramides_gauss_laplace.append((pyramid_gauss, pyramid_laplace))\n",
    "\t\n",
    "\tls = []\n",
    "\tfor image_1_pyramid_laplace, image_2_pyramid_laplace in zip(tuples_pyramides_gauss_laplace[0][1], tuples_pyramides_gauss_laplace[1][1]):\n",
    "\t\tls.append(np.hstack((image_1_pyramid_laplace[:, 0:image_1_pyramid_laplace.shape[1]//2], image_2_pyramid_laplace[:, image_1_pyramid_laplace.shape[1]//2:])))\n",
    "\t\n",
    "\timage_blended=ls[0]\n",
    "\tfor i in range(1, rg):\n",
    "\t\timage_blended=cv.pyrUp(image_blended)\n",
    "\t\timage_blended = cv.add(image_blended, ls[i])\n",
    "\t\n",
    "\treturn image_blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Blended cup image\", blendImages(images[0], images[1]))\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача №3 - Найди клетки\n",
    "\n",
    "Даны снимки раковых клеток. Существует задача - определить стадию рака клетки по такому изображению. Для того, чтобы подойти к решению классификации рака клетки, необходимо сначала подготовить данные.\n",
    "\n",
    "Исходные изображения в реальных задачах могут быть очень большого размера (более 20000 px). Однако из визуального анализа можно заметить, что большая часть этих снимков пустая и не несет в себе полезную информацию.\n",
    "\n",
    "Ваша задача выделить небольшие ячейки изображений из исходного так, чтобы на ячейках было только изображение клетки.\n",
    "\n",
    "Пример исходного изображения и нарезанных ячеек клетки.\n",
    "<img src=\"img/cell_example.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "В качестве аргументов у функции будут значения:\n",
    "1. исходное изображние;\n",
    "2. размер ячейки;\n",
    "3. количество ячеек.\n",
    "\n",
    "__Доп вопрос__ - как можно выяснить какие нужны значения аргументов, чтобы они подходили для большинства исходных снимков?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методом проб и ошибок. Но рассмотрим бимодальное изображение (проще говоря, бимодальное изображение - это изображение, гистограмма которого имеет два пика). Для этого изображения мы можем приблизительно принять значение в середине этих пиков в качестве порогового значения, верно? Это то, что делает бинаризация Оцу. Таким образом, простыми словами, он автоматически вычисляет пороговое значение из гистограммы изображения для бимодального изображения. (Для изображений, которые не являются бимодальными, бинаризация не будет точной.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_cells=\"lab3/cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=readImagesFromDirectory(path_images_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCells(image : np.ndarray, cell_size : tuple[int, int], cells_count : int) -> list[np.ndarray]:\n",
    "    _, binary = cv.threshold(cv.cvtColor(image, cv.COLOR_BGR2GRAY), 127, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "    contours, _ = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    images_cell = []\n",
    "    for contour in contours:\n",
    "        location_x, location_y, width, height = cv.boundingRect(contour)\n",
    "        cell = image[location_y:location_y+height, location_x:location_x+width]\n",
    "        images_cell.append(cv.resize(cell, (cell_size[0], cell_size[1])))\n",
    "        if len(images_cell) >= cells_count:\n",
    "            break\n",
    "    \n",
    "    return images_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:47:11.011295Z",
     "start_time": "2020-07-15T04:47:11.007494Z"
    }
   },
   "outputs": [],
   "source": [
    "for image in images:\n",
    "\timages_cell=getCells(image, (20, 20), 50)\n",
    "\ti=0\n",
    "\tfor cell in images_cell:\n",
    "\t\tcv.imshow(f\"Cell {i}\", cell)\n",
    "\t\ti+=1\n",
    "\tcv.waitKey()\n",
    "\tcv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "_Feature",
    "builtin_function_or_method",
    "function",
    "instance",
    "module"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
